{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering for KKBox Churn Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I already mentioned in the **Literature Survey** that feature engineering is critical for this challenge. And without good feature engineering I cannot achieve my objective. The majority of the features comming from univariate analysis that I performed. And few from the interaction of two variables.\n",
    "\n",
    "I can start with some of the basic feature engineering, which include some basic statistics and interactive features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the train and test datasets-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the files\n",
    "\n",
    "train_dataset = pd.read_csv('Preprocessed Data/train.csv')\n",
    "test_dataset = pd.read_csv('Preprocessed Data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>is_churn</th>\n",
       "      <th>city</th>\n",
       "      <th>bd</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>registration_init_time</th>\n",
       "      <th>payment_method_id</th>\n",
       "      <th>payment_plan_days</th>\n",
       "      <th>plan_list_price</th>\n",
       "      <th>actual_amount_paid</th>\n",
       "      <th>is_auto_renew</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>membership_expire_date</th>\n",
       "      <th>is_cancel</th>\n",
       "      <th>date</th>\n",
       "      <th>num_25</th>\n",
       "      <th>num_50</th>\n",
       "      <th>num_75</th>\n",
       "      <th>num_985</th>\n",
       "      <th>num_100</th>\n",
       "      <th>num_unq</th>\n",
       "      <th>total_secs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ugx0CjOMzazClkFzU2xasmDZaoIqOUAZPsH1q0teWCg=</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2013-12-23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2017-03-16</td>\n",
       "      <td>2017-04-19</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2017-03-05</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>17599.893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ugx0CjOMzazClkFzU2xasmDZaoIqOUAZPsH1q0teWCg=</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2013-12-23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2017-03-16</td>\n",
       "      <td>2017-04-19</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8830.433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ugx0CjOMzazClkFzU2xasmDZaoIqOUAZPsH1q0teWCg=</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2013-12-23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2017-03-16</td>\n",
       "      <td>2017-04-19</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2017-03-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7883.313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ugx0CjOMzazClkFzU2xasmDZaoIqOUAZPsH1q0teWCg=</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2013-12-23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2017-03-16</td>\n",
       "      <td>2017-04-19</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2017-03-16</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9029.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ugx0CjOMzazClkFzU2xasmDZaoIqOUAZPsH1q0teWCg=</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2013-12-23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2017-03-16</td>\n",
       "      <td>2017-04-19</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2017-03-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1870.110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  is_churn  city    bd  gender  \\\n",
       "0  ugx0CjOMzazClkFzU2xasmDZaoIqOUAZPsH1q0teWCg=         1   5.0  28.0     1.0   \n",
       "1  ugx0CjOMzazClkFzU2xasmDZaoIqOUAZPsH1q0teWCg=         1   5.0  28.0     1.0   \n",
       "2  ugx0CjOMzazClkFzU2xasmDZaoIqOUAZPsH1q0teWCg=         1   5.0  28.0     1.0   \n",
       "3  ugx0CjOMzazClkFzU2xasmDZaoIqOUAZPsH1q0teWCg=         1   5.0  28.0     1.0   \n",
       "4  ugx0CjOMzazClkFzU2xasmDZaoIqOUAZPsH1q0teWCg=         1   5.0  28.0     1.0   \n",
       "\n",
       "   registered_via registration_init_time  payment_method_id  \\\n",
       "0             3.0             2013-12-23                0.0   \n",
       "1             3.0             2013-12-23                0.0   \n",
       "2             3.0             2013-12-23                0.0   \n",
       "3             3.0             2013-12-23                0.0   \n",
       "4             3.0             2013-12-23                0.0   \n",
       "\n",
       "   payment_plan_days  plan_list_price  actual_amount_paid  is_auto_renew  \\\n",
       "0               30.0            149.0               149.0            2.0   \n",
       "1               30.0            149.0               149.0            2.0   \n",
       "2               30.0            149.0               149.0            2.0   \n",
       "3               30.0            149.0               149.0            2.0   \n",
       "4               30.0            149.0               149.0            2.0   \n",
       "\n",
       "  transaction_date membership_expire_date  is_cancel        date  num_25  \\\n",
       "0       2017-03-16             2017-04-19        2.0  2017-03-05     7.0   \n",
       "1       2017-03-16             2017-04-19        2.0  2017-03-01     2.0   \n",
       "2       2017-03-16             2017-04-19        2.0  2017-03-19     0.0   \n",
       "3       2017-03-16             2017-04-19        2.0  2017-03-16    15.0   \n",
       "4       2017-03-16             2017-04-19        2.0  2017-03-10     0.0   \n",
       "\n",
       "   num_50  num_75  num_985  num_100  num_unq  total_secs  \n",
       "0     0.0     3.0      0.0     71.0     68.0   17599.893  \n",
       "1     0.0     0.0      1.0     21.0     16.0    8830.433  \n",
       "2     0.0     0.0      0.0     34.0     17.0    7883.313  \n",
       "3     0.0     0.0      1.0     38.0     17.0    9029.227  \n",
       "4     0.0     0.0      0.0      8.0      8.0    1870.110  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting head of train file\n",
    "pd.set_option('display.max_columns', 100)\n",
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>is_churn</th>\n",
       "      <th>city</th>\n",
       "      <th>bd</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>registration_init_time</th>\n",
       "      <th>payment_method_id</th>\n",
       "      <th>payment_plan_days</th>\n",
       "      <th>plan_list_price</th>\n",
       "      <th>actual_amount_paid</th>\n",
       "      <th>is_auto_renew</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>membership_expire_date</th>\n",
       "      <th>is_cancel</th>\n",
       "      <th>date</th>\n",
       "      <th>num_25</th>\n",
       "      <th>num_50</th>\n",
       "      <th>num_75</th>\n",
       "      <th>num_985</th>\n",
       "      <th>num_100</th>\n",
       "      <th>num_unq</th>\n",
       "      <th>total_secs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4n+fXlyJvfQnTeKXTWT507Ll4JVYGrOC8LHCfwBmPE4=</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2015-07-18</td>\n",
       "      <td>41.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-03-18</td>\n",
       "      <td>2017-04-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-03-16</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3880.765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aNmbC1GvFUxQyQUidCVmfbQ0YeCuwkPzEdQ0RwWyeZM=</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2005-10-30</td>\n",
       "      <td>34.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-03-08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3880.765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aNmbC1GvFUxQyQUidCVmfbQ0YeCuwkPzEdQ0RwWyeZM=</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2005-10-30</td>\n",
       "      <td>34.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-03-19</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>10333.911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aNmbC1GvFUxQyQUidCVmfbQ0YeCuwkPzEdQ0RwWyeZM=</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2005-10-30</td>\n",
       "      <td>34.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3880.765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aNmbC1GvFUxQyQUidCVmfbQ0YeCuwkPzEdQ0RwWyeZM=</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2005-10-30</td>\n",
       "      <td>34.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-03-07</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3826.011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  is_churn  city    bd  gender  \\\n",
       "0  4n+fXlyJvfQnTeKXTWT507Ll4JVYGrOC8LHCfwBmPE4=         0   1.0  28.0     0.0   \n",
       "1  aNmbC1GvFUxQyQUidCVmfbQ0YeCuwkPzEdQ0RwWyeZM=         0   4.0  28.0     1.0   \n",
       "2  aNmbC1GvFUxQyQUidCVmfbQ0YeCuwkPzEdQ0RwWyeZM=         0   4.0  28.0     1.0   \n",
       "3  aNmbC1GvFUxQyQUidCVmfbQ0YeCuwkPzEdQ0RwWyeZM=         0   4.0  28.0     1.0   \n",
       "4  aNmbC1GvFUxQyQUidCVmfbQ0YeCuwkPzEdQ0RwWyeZM=         0   4.0  28.0     1.0   \n",
       "\n",
       "   registered_via registration_init_time  payment_method_id  \\\n",
       "0             7.0             2015-07-18               41.0   \n",
       "1             9.0             2005-10-30               34.0   \n",
       "2             9.0             2005-10-30               34.0   \n",
       "3             9.0             2005-10-30               34.0   \n",
       "4             9.0             2005-10-30               34.0   \n",
       "\n",
       "   payment_plan_days  plan_list_price  actual_amount_paid  is_auto_renew  \\\n",
       "0               30.0             99.0                99.0            1.0   \n",
       "1               30.0            149.0               149.0            1.0   \n",
       "2               30.0            149.0               149.0            1.0   \n",
       "3               30.0            149.0               149.0            1.0   \n",
       "4               30.0            149.0               149.0            1.0   \n",
       "\n",
       "  transaction_date membership_expire_date  is_cancel        date  num_25  \\\n",
       "0       2017-03-18             2017-04-18        0.0  2017-03-16     2.0   \n",
       "1       2017-03-31             2017-04-30        0.0  2017-03-08     2.0   \n",
       "2       2017-03-31             2017-04-30        0.0  2017-03-19     2.0   \n",
       "3       2017-03-31             2017-04-30        0.0  2017-03-01    15.0   \n",
       "4       2017-03-31             2017-04-30        0.0  2017-03-07     3.0   \n",
       "\n",
       "   num_50  num_75  num_985  num_100  num_unq  total_secs  \n",
       "0     0.0     0.0      0.0     14.0     16.0    3880.765  \n",
       "1     4.0     0.0      0.0     14.0     16.0    3880.765  \n",
       "2     2.0     3.0      0.0     34.0     57.0   10333.911  \n",
       "3     2.0     0.0      0.0     14.0     16.0    3880.765  \n",
       "4     2.0     0.0      1.0     13.0     16.0    3826.011  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting head of test file\n",
    "pd.set_option('display.max_columns', 100)\n",
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature - 1 (getting weekday from date)\n",
    "\n",
    "# getting weekday from the date feature for train data\n",
    "train_dataset['date'] = pd.to_datetime(train_dataset['date'], errors='coerce')\n",
    "train_dataset['day_of_the_week'] = train_dataset['date'].dt.day_name().values\n",
    "\n",
    "# getting weekday from the date feature for test data\n",
    "test_dataset['date'] = pd.to_datetime(test_dataset['date'], errors='coerce')\n",
    "test_dataset['day_of_the_week'] = test_dataset['date'].dt.day_name().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature - 2 (checking for the weekend)\n",
    "\n",
    "train_dataset['is_weekend'] = train_dataset['day_of_the_week'].apply(lambda x: 1 if (x == 'Saturday') or (x == 'Sunday') else 0)\n",
    "test_dataset['is_weekend'] = test_dataset['day_of_the_week'].apply(lambda x: 1 if (x == 'Saturday') or (x == 'Sunday') else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature - 3 (checking for the weekday)\n",
    "\n",
    "train_dataset['is_weekday'] = train_dataset['is_weekend'].apply(lambda x: 1 if (x == 0) else 0)\n",
    "test_dataset['is_weekday'] = test_dataset['is_weekend'].apply(lambda x: 1 if (x == 0) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 47s, sys: 26.2 s, total: 11min 13s\n",
      "Wall time: 11min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Feature - 4 to 12 (sum based features)\n",
    "# Feature - 13 to 19 (mean based features)\n",
    "# Feature - 20 to 27 (standard deviation based features)\n",
    "# Feature - 28 (nunique based feature)\n",
    "# Feature - 29 and 30 (min and max based features)\n",
    "# Feature - 31 to 33 (mean based features for transaction)\n",
    "# Feature - 34 (transaction count)\n",
    "# Feature - 35 (transaction date max)\n",
    "# Feature - 36 (membership expiry date max)\n",
    "# Feature - 37 (membership expiry date count)\n",
    "\n",
    "def std(x):\n",
    "    '''finding standard deviation using numpy,\n",
    "    to avoid getting nan values'''\n",
    "    return np.std(x)\n",
    "\n",
    "# grouping them together for train data\n",
    "temp_df_train = train_dataset.groupby('msno').agg(num_25_sum=('num_25', 'sum'),\n",
    "                                num_50_sum=('num_50', 'sum'),\n",
    "                                num_75_sum=('num_75', 'sum'),\n",
    "                                num_985_sum=('num_985', 'sum'),\n",
    "                                num_100_sum=('num_100', 'sum'),\n",
    "                                num_unq_sum=('num_unq', 'sum'),\n",
    "                                total_secs_sum=('total_secs', 'sum'),\n",
    "                                is_weekend_sum=('is_weekend', 'sum'),\n",
    "                                is_weekday_sum=('is_weekday', 'sum'),\n",
    "                                num_25_mean=('num_25', 'mean'),\n",
    "                                num_50_mean=('num_50', 'mean'),\n",
    "                                num_75_mean=('num_75', 'mean'),\n",
    "                                num_985_mean=('num_985', 'mean'),\n",
    "                                num_100_mean=('num_100', 'mean'),\n",
    "                                num_unq_mean=('num_unq', 'mean'),\n",
    "                                total_secs_mean=('total_secs', 'mean'),\n",
    "                                num_25_std=('num_25', std),\n",
    "                                num_50_std=('num_50', std),\n",
    "                                num_75_std=('num_75', std),\n",
    "                                num_985_std=('num_985', std),\n",
    "                                num_100_std=('num_100', std),\n",
    "                                num_unq_std=('num_unq', std),\n",
    "                                total_secs_std=('total_secs', std),\n",
    "                                active_days=('date', 'nunique'),\n",
    "                                date_min=('date', 'min'),\n",
    "                                date_max=('date', 'max'),\n",
    "                                payment_plan_days_mean=('payment_plan_days', 'mean'),\n",
    "                                plan_list_price_mean=('plan_list_price', 'mean'),\n",
    "                                actual_amount_paid_mean=('actual_amount_paid', 'mean'),\n",
    "                                transaction_date_count=('transaction_date', 'nunique'),\n",
    "                                transaction_date_max=('transaction_date', 'max'),\n",
    "                                membership_expire_date_max=('membership_expire_date', 'max'),\n",
    "                                membership_expire_count=('membership_expire_date', 'nunique'))\n",
    "# merging them with the train dataset\n",
    "train_dataset = pd.merge(train_dataset, temp_df_train, on='msno', how='left')\n",
    "\n",
    "# grouping them together for test data\n",
    "temp_df_test = test_dataset.groupby('msno').agg(num_25_sum=('num_25', 'sum'),\n",
    "                                num_50_sum=('num_50', 'sum'),\n",
    "                                num_75_sum=('num_75', 'sum'),\n",
    "                                num_985_sum=('num_985', 'sum'),\n",
    "                                num_100_sum=('num_100', 'sum'),\n",
    "                                num_unq_sum=('num_unq', 'sum'),\n",
    "                                total_secs_sum=('total_secs', 'sum'),\n",
    "                                is_weekend_sum=('is_weekend', 'sum'),\n",
    "                                is_weekday_sum=('is_weekday', 'sum'),\n",
    "                                num_25_mean=('num_25', 'mean'),\n",
    "                                num_50_mean=('num_50', 'mean'),\n",
    "                                num_75_mean=('num_75', 'mean'),\n",
    "                                num_985_mean=('num_985', 'mean'),\n",
    "                                num_100_mean=('num_100', 'mean'),\n",
    "                                num_unq_mean=('num_unq', 'mean'),\n",
    "                                total_secs_mean=('total_secs', 'mean'),\n",
    "                                num_25_std=('num_25', std),\n",
    "                                num_50_std=('num_50', std),\n",
    "                                num_75_std=('num_75', std),\n",
    "                                num_985_std=('num_985', std),\n",
    "                                num_100_std=('num_100', std),\n",
    "                                num_unq_std=('num_unq', std),\n",
    "                                total_secs_std=('total_secs', std),\n",
    "                                active_days=('date', 'nunique'),\n",
    "                                date_min=('date', 'min'),\n",
    "                                date_max=('date', 'max'),\n",
    "                                payment_plan_days_mean=('payment_plan_days', 'mean'),\n",
    "                                plan_list_price_mean=('plan_list_price', 'mean'),\n",
    "                                actual_amount_paid_mean=('actual_amount_paid', 'mean'),\n",
    "                                transaction_date_count=('transaction_date', 'nunique'),\n",
    "                                transaction_date_max=('transaction_date', 'max'),\n",
    "                                membership_expire_date_max=('membership_expire_date', 'max'),\n",
    "                                membership_expire_count=('membership_expire_date', 'nunique'))\n",
    "# merging them with the test dataset\n",
    "test_dataset = pd.merge(test_dataset, temp_df_test, on='msno', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature - 38 (activity period)\n",
    "\n",
    "train_dataset['date_min'] = pd.to_datetime(train_dataset['date_min'], errors='coerce')\n",
    "train_dataset['date_max'] = pd.to_datetime(train_dataset['date_max'], errors='coerce')\n",
    "\n",
    "test_dataset['date_min'] = pd.to_datetime(test_dataset['date_min'], errors='coerce')\n",
    "test_dataset['date_max'] = pd.to_datetime(test_dataset['date_max'], errors='coerce')\n",
    "\n",
    "train_dataset['activity_period'] = (train_dataset['date_max'] - train_dataset['date_min']).dt.days + 1\n",
    "test_dataset['activity_period'] = (test_dataset['date_max'] - test_dataset['date_min']).dt.days + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature - 39 (inactive days)\n",
    "\n",
    "train_dataset['inactive_days'] = train_dataset['date'].nunique() - train_dataset['active_days']\n",
    "test_dataset['inactive_days'] = test_dataset['date'].nunique() - test_dataset['active_days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature - 40 (rare behaviour)\n",
    "# 0 (for not rare user) and 1 (for rare user)\n",
    "\n",
    "train_dataset['is_rare'] = train_dataset['active_days'].apply(lambda x: 0 if (x > 1) else 1)\n",
    "test_dataset['is_rare'] = test_dataset['active_days'].apply(lambda x: 0 if (x > 1) else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature - 41 (average time per day)\n",
    "\n",
    "train_dataset['avg_time_perday'] = train_dataset['total_secs_sum'] / train_dataset['active_days']\n",
    "test_dataset['avg_time_perday'] = test_dataset['total_secs_sum'] / test_dataset['active_days']\n",
    "\n",
    "\n",
    "# Feature - 42 (unique tracks played per day)\n",
    "\n",
    "train_dataset['unq_track_perday'] = round(train_dataset['num_unq_sum'] / train_dataset['active_days'])\n",
    "test_dataset['unq_track_perday'] = round(test_dataset['num_unq_sum'] / test_dataset['active_days'])\n",
    "\n",
    "\n",
    "# Feature - 43 (tracks played till 25% length per day)\n",
    "\n",
    "train_dataset['till_25_perday'] = round(train_dataset['num_25_sum'] / train_dataset['active_days'])\n",
    "test_dataset['till_25_perday'] = round(test_dataset['num_25_sum'] / test_dataset['active_days'])\n",
    "\n",
    "\n",
    "# Feature - 44 (tracks played till 50% length per day)\n",
    "\n",
    "train_dataset['till_50_perday'] = round(train_dataset['num_50_sum'] / train_dataset['active_days'])\n",
    "test_dataset['till_50_perday'] = round(test_dataset['num_50_sum'] / test_dataset['active_days'])\n",
    "\n",
    "\n",
    "# Feature - 45 (tracks played till 75% length per day)\n",
    "\n",
    "train_dataset['till_75_perday'] = round(train_dataset['num_75_sum'] / train_dataset['active_days'])\n",
    "test_dataset['till_75_perday'] = round(test_dataset['num_75_sum'] / test_dataset['active_days'])\n",
    "\n",
    "\n",
    "# Feature - 46 (tracks played till 98.5% length per day)\n",
    "\n",
    "train_dataset['till_985_perday'] = round(train_dataset['num_985_sum'] / train_dataset['active_days'])\n",
    "test_dataset['till_985_perday'] = round(test_dataset['num_985_sum'] / test_dataset['active_days'])\n",
    "\n",
    "\n",
    "# Feature - 47 (tracks played till 100% length per day)\n",
    "\n",
    "train_dataset['till_full_perday'] = round(train_dataset['num_100_sum'] / train_dataset['active_days'])\n",
    "test_dataset['till_full_perday'] = round(test_dataset['num_100_sum'] / test_dataset['active_days'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature - 48 (discount)\n",
    "\n",
    "train_dataset['discount'] = train_dataset['plan_list_price'] - train_dataset['actual_amount_paid']\n",
    "test_dataset['discount'] = test_dataset['plan_list_price'] - test_dataset['actual_amount_paid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0.,  149.,  180., -149.,   30., -119., -129.,  120.,   20.,\n",
       "         50., -100.,   -1.,   99.,  129.,    1.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset['discount'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since there are several values which are less than 0 for various reasons\n",
    "# so it's always good to set a lower limit, here I can set 0\n",
    "train_dataset['discount'] = train_dataset['discount'].clip(lower=0)\n",
    "test_dataset['discount'] = test_dataset['discount'].clip(lower=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature - 49 (is_discount)\n",
    "\n",
    "train_dataset['is_discount'] = train_dataset['discount'].apply(lambda x: 1 if (x > 0) else 0)\n",
    "test_dataset['is_discount'] = test_dataset['discount'].apply(lambda x: 1 if (x > 0) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature - 50 (days since final login)\n",
    "# Threshold that I set here is the last date, which is 31-03-2017\n",
    "\n",
    "train_dataset['days_since_last_login'] = (pd.to_datetime(train_dataset['date'].unique().max(), errors='coerce') - train_dataset['date_max']).dt.days\n",
    "test_dataset['days_since_last_login'] = (pd.to_datetime(test_dataset['date'].unique().max(), errors='coerce') - test_dataset['date_max']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset['membership_expire_date_max'] = pd.to_datetime(train_dataset['membership_expire_date_max'], errors='coerce')\n",
    "test_dataset['membership_expire_date_max'] = pd.to_datetime(test_dataset['membership_expire_date_max'], errors='coerce')\n",
    "\n",
    "train_dataset['days_left'] = (train_dataset['membership_expire_date_max'] - pd.to_datetime(train_dataset['date'].unique().max(), errors='coerce')).dt.days\n",
    "test_dataset['days_left'] = (test_dataset['membership_expire_date_max'] - pd.to_datetime(test_dataset['date'].unique().max(), errors='coerce')).dt.days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since there are many negative values so I can set them to 0\n",
    "train_dataset['days_left'] = train_dataset['days_left'].clip(lower=0)\n",
    "test_dataset['days_left'] = test_dataset['days_left'].clip(lower=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature - 51 (Loyality range)\n",
    "\n",
    "train_dataset['transaction_date_max'] = pd.to_datetime(train_dataset['transaction_date_max'], errors='coerce')\n",
    "test_dataset['transaction_date_max'] = pd.to_datetime(test_dataset['transaction_date_max'], errors='coerce')\n",
    "train_dataset['registration_init_time'] = pd.to_datetime(train_dataset['registration_init_time'], errors='coerce')\n",
    "test_dataset['registration_init_time'] = pd.to_datetime(test_dataset['registration_init_time'], errors='coerce')\n",
    "\n",
    "train_dataset['layality_range'] = (train_dataset['transaction_date_max'] - train_dataset['registration_init_time']).dt.days\n",
    "test_dataset['layality_range'] = (test_dataset['transaction_date_max'] - test_dataset['registration_init_time']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature - 52 (price per day)\n",
    "\n",
    "train_dataset['Perday_price'] = train_dataset['actual_amount_paid'] / train_dataset['payment_plan_days']\n",
    "test_dataset['Perday_price'] = test_dataset['actual_amount_paid'] / test_dataset['payment_plan_days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature - 53 (days since final transaction)\n",
    "\n",
    "train_dataset['days_since_final_transaction'] = (pd.to_datetime(train_dataset['date'].unique().max(), errors='coerce') - train_dataset['transaction_date_max']).dt.days\n",
    "test_dataset['days_since_final_transaction'] = (pd.to_datetime(test_dataset['date'].unique().max(), errors='coerce') - test_dataset['transaction_date_max']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['msno', 'is_churn', 'city', 'bd', 'gender', 'registered_via',\n",
       "       'registration_init_time', 'payment_method_id', 'payment_plan_days',\n",
       "       'plan_list_price', 'actual_amount_paid', 'is_auto_renew',\n",
       "       'transaction_date', 'membership_expire_date', 'is_cancel', 'date',\n",
       "       'num_25', 'num_50', 'num_75', 'num_985', 'num_100', 'num_unq',\n",
       "       'total_secs', 'day_of_the_week', 'is_weekend', 'is_weekday',\n",
       "       'num_25_sum', 'num_50_sum', 'num_75_sum', 'num_985_sum', 'num_100_sum',\n",
       "       'num_unq_sum', 'total_secs_sum', 'is_weekend_sum', 'is_weekday_sum',\n",
       "       'num_25_mean', 'num_50_mean', 'num_75_mean', 'num_985_mean',\n",
       "       'num_100_mean', 'num_unq_mean', 'total_secs_mean', 'num_25_std',\n",
       "       'num_50_std', 'num_75_std', 'num_985_std', 'num_100_std', 'num_unq_std',\n",
       "       'total_secs_std', 'active_days', 'date_min', 'date_max',\n",
       "       'payment_plan_days_mean', 'plan_list_price_mean',\n",
       "       'actual_amount_paid_mean', 'transaction_date_count',\n",
       "       'transaction_date_max', 'membership_expire_date_max',\n",
       "       'membership_expire_count', 'activity_period', 'inactive_days',\n",
       "       'is_rare', 'avg_time_perday', 'unq_track_perday', 'till_25_perday',\n",
       "       'till_50_perday', 'till_75_perday', 'till_985_perday',\n",
       "       'till_full_perday', 'discount', 'is_discount', 'days_since_last_login',\n",
       "       'days_left', 'layality_range', 'Perday_price',\n",
       "       'days_since_final_transaction'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all features in train data\n",
    "train_dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Since data is very large so storing them by changing the default datatype to custom datatype can reduce the size of new csv files.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference: https://medium.com/@vincentteyssier/optimizing-the-size-of-a-pandas-dataframe-for-low-memory-environment-5f07db3d72e\n",
    "# reference: https://numpy.org/doc/stable/reference/generated/numpy.iinfo.html\n",
    "# reference: https://numpy.org/doc/stable/reference/generated/numpy.finfo.html\n",
    "\n",
    "def datatype_changer(dataset):\n",
    "    # iterating through all the columns in the dataframe\n",
    "    for col in dataset.columns:\n",
    "        # getting column's datatype\n",
    "        col_type = dataset[col].dtype\n",
    "        \n",
    "        # checking if datatype of column is 'object' or not\n",
    "        # if column type is not object\n",
    "        if (col_type == int) or (col_type == float):\n",
    "            # getting minimum value of a column\n",
    "            min_val = dataset[col].min()\n",
    "            # getting maximum value of a column\n",
    "            max_val = dataset[col].max()\n",
    "            # checking whether the datatype contain first 3 characters as int or not, if int\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                # cheking the minimal and maximal value for int8, int16, int32 and int64 in numpy\n",
    "                if min_val > np.iinfo(np.int8).min and max_val < np.iinfo(np.int8).max:\n",
    "                    dataset[col] = dataset[col].astype(np.int8)\n",
    "                elif min_val > np.iinfo(np.int16).min and max_val < np.iinfo(np.int16).max:\n",
    "                    dataset[col] = dataset[col].astype(np.int16)\n",
    "                elif min_val > np.iinfo(np.int32).min and max_val < np.iinfo(np.int32).max:\n",
    "                    dataset[col] = dataset[col].astype(np.int32)\n",
    "                else:\n",
    "                    dataset[col] = dataset[col].astype(np.int64)\n",
    "            else:\n",
    "                # if it is non int, which is ultimately float\n",
    "                # cheking the minimal and maximal value for float16, float32 and float64 in numpy\n",
    "                if min_val > np.finfo(np.float16).min and max_val < np.finfo(np.float16).max:\n",
    "                    dataset[col] = dataset[col].astype(np.float16)\n",
    "                elif min_val > np.finfo(np.float32).min and max_val < np.finfo(np.float32).max:\n",
    "                    dataset[col] = dataset[col].astype(np.float32)\n",
    "                else:\n",
    "                    dataset[col] = dataset[col].astype(np.float64)\n",
    "        else:\n",
    "            # keeping rest of them to category datatype instead of object\n",
    "            dataset[col] = dataset[col].astype('category')\n",
    "            \n",
    "    # returning head of the dataframe\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datatype_changer(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = datatype_changer(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving train file\n",
    "\n",
    "train_dataset.to_csv('Data after Feature Engineering/train_FA.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving test file\n",
    "\n",
    "test_dataset.to_csv('Data after Feature Engineering/test_FA.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary - \n",
    "\n",
    "The main highlight of the feature engineering is: -\n",
    "\n",
    "**1. Almost all of the important features I achieved from transactions and user logs.**\n",
    "\n",
    "**2. Basic stats features might be useful, that's why I extracted them.**\n",
    "\n",
    "**3. I also created some interactive features, few of them comes for the litererature survey, and few by observing data and existing features.**\n",
    "\n",
    "**4. Ultimately at the end I have 72 features. Total 74 but one is 'msno' and second is 'is_churn'.**\n",
    "\n",
    "**5. The size of the dataset is very large. 1) train file size - 9.61 GB and 2) test file size - 7.79 GB.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
